# ğŸ§  Policy Cancellation Prediction: Enhancing Customer Retention

## ğŸš€ Executive Summary

This project developed an **XGBoost machine learning model** to predict which **auto insurance policies** are most likely to be canceled within **180 days**.

By tuning the modelâ€™s prediction threshold, the team increased the number of **identified high-risk policies by 3.6Ã—** compared to the default setting â€” shifting focus from perfect accuracy to **maximum business value**.  
This enables the retention team to **intervene proactively**, potentially saving **millions in lost premium revenue**.

**Key Findings**
- **Risk Profile is the #1 Driver:** A customerâ€™s *Risk Group* is the strongest predictor of policy cancellation.  
- **Contact Method Matters:** Policies initiated through a **Call Center or Agent** show better retention than those started online.  
- **Model is Actionable:** The tuned model captures **58% of all actual cancellations**, giving the business a high-impact target list for retention efforts.

---

## ğŸ“Š Exploratory Data Insights (EDA)

**Retention Rate by Market Channel**  
While online policies show the highest retention rate (81.8%), they also account for the majority of total policies. Channels like Agent and Search exhibit lower retention rates â€” ideal candidates for targeted retention.

![Policy Retention Rate by Market Channel](eda_retention_by_channel.png)

**Premium Trend Analysis**  
Monthly billed premiums have consistently increased over the last three policy years, signaling higher average policy value or greater product complexity.

![Monthly Mean of Total Billed Premium](eda_premium_trends.png)

---

## âš™ï¸ Model Performance

Among all models tested â€” Logistic Regression, Random Forest, AdaBoost, and XGBoost â€” the **XGBoost classifier** delivered the **best performance**.  
It achieved a **macro F1-score of 0.57** and an **AUC-ROC of 0.73**, demonstrating robust generalization and high reliability.

**Precision-Recall Tuning for Business Impact**  
Because of class imbalance, a default 0.50 probability threshold missed many cancellations.  
By optimizing the threshold to **0.211**, the recall increased substantially while keeping precision stable â€” identifying **3.6Ã— more high-risk customers** than before.

![Precision-Recall Curve](model_precision_recall_curve.png)

**Confusion Matrix (After Tuning)**  
- True Negatives: 45,495  
- False Positives: 14,851  
- False Negatives: 5,910  
- True Positives: 8,115  

**Business Impact:**  
The **8,115 True Positives** represent real customers at risk â€” a ready-to-act retention list worth significant premium value.

![Confusion Matrix](model_confusion_matrix.png)

---

## ğŸ’¡ Key Drivers and Interpretability

Understanding *why* customers cancel is critical for business strategy.

**Top Drivers of Cancellation:**
- **Customer Risk Group:** High-risk customers are more likely to cancel.  
- **Initial Contact Method:** Policies initiated via phone retain better than online.  
- **Full Payment Indicator:** Full-pay customers demonstrate stronger loyalty.  
- **Telematics Enrollment:** Drivers in tracking programs have higher retention.  
- **Policy Cleanliness:** Customers with prior accidents or violations are more likely to cancel.  
- **Policy Bundling:** Customers holding both Auto and Home policies are more stable.  
- **Vehicle Count:** Multi-vehicle policies have slightly higher cancellation risk.

![Top Feature Importance for Policy Cancellation](impact_feature_importance.png)

**SHAP Insights:**  
- **Customer Lifetime Value Group:** Long-tenure, high-value customers show reduced cancellation risk.  
- **Risk Group:** High-risk scores strongly elevate cancellation probability.

![SHAP Summary Plot](impact_shap_summary.png)

---

## ğŸ§© Data and Modeling Pipeline

A structured and reproducible ML pipeline ensured consistent results:  
- 371,000+ records and 38 variables processed.  
- Imputed missing data with median (numeric) and â€œUnknownâ€ (categorical).  
- Log-transformed skewed features and scaled numerical variables.  
- Used **Stratified 80/20 train-test split** to preserve cancellation ratios.  
- Evaluated models using **5-fold cross-validation** for balanced performance assessment.  
- Removed highly correlated variables to avoid redundancy.  
- Excluded SMOTE (though tested) to prevent overfitting in production.

---

## â­ï¸ Recommendations

1. **Targeted Outreach:** Immediately contact the **8,115 predicted high-risk customers** with personalized offers or review calls.  
2. **Risk Group Deep Dive:** Investigate why the top-risk customers cancel and refine pricing or engagement strategies.  
3. **Channel Optimization:** Increase marketing focus on **Call Center** and **Agent-initiated** policies.  
4. **Telematics Expansion:** Incentivize telematics adoption for moderate-risk groups to enhance retention.  
5. **Continuous Learning:** Retrain and monitor the model quarterly to maintain predictive accuracy.

---

## ğŸ§° Tools and Technologies

- **Languages:** Python  
- **Libraries:** XGBoost, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn  
- **Techniques:** Cross-Validation, Threshold Optimization, Precision-Recall Analysis, SHAP, Feature Importance  
- **Performance:** AUC-ROC = 0.73 | F1-Score = 0.57 | Recall = 0.58  
- **Dataset:** 371,859 auto policies, 38 features

---

## ğŸ§  How to Run the Project

**1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/<your-username>/policy-cancellation-prediction.git
cd policy-cancellation-prediction
```

**2ï¸âƒ£ Create a Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate    # For Mac/Linux
venv\Scripts\activate       # For Windows
```

**3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

**4ï¸âƒ£ Run the Notebook**
Open the Jupyter notebook:
```bash
jupyter notebook
```
Run `model_pipeline.ipynb` to reproduce preprocessing, model training, and evaluation.

---

## ğŸ—‚ï¸ Repository Structure

```
policy-cancellation-prediction/
â”‚
â”œâ”€â”€ data/                         # Raw or sample dataset (if permitted)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda_analysis.ipynb        # Exploratory Data Analysis
â”‚   â”œâ”€â”€ model_pipeline.ipynb      # Model training and threshold tuning
â”‚
â”œâ”€â”€ visuals/
â”‚   â”œâ”€â”€ eda_retention_by_channel.png
â”‚   â”œâ”€â”€ eda_premium_trends.png
â”‚   â”œâ”€â”€ model_precision_recall_curve.png
â”‚   â”œâ”€â”€ model_confusion_matrix.png
â”‚   â”œâ”€â”€ impact_feature_importance.png
â”‚   â”œâ”€â”€ impact_shap_summary.png
â”‚
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ README.md                     # Project overview (this file)
â””â”€â”€ LICENSE                       # License (if applicable)
```

---

## ğŸ‘¥ Team

**The Hartford Group 3**  
Aswin Ganesh Venkatramanan â€¢ Prince Kodua â€¢ Soumya Vadla â€¢ Xinyu Yuan  
*University of Connecticut â€“ MS in Data Science Capstone Project*

---

## ğŸ† Highlights

- Identified **8,000+ high-risk policies** for immediate retention action.  
- Improved recall by **3.6Ã—** through optimized thresholding.  
- Delivered **data-driven insights** enabling strategic retention decisions.
